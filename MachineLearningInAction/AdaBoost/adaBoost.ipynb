{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adaptive boosting:是一种集成方法，通过组合多个弱分类器的分类结果，进行加权求和的分类结果\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadSimpData():\n",
    "     datMat = np.matrix(\n",
    "        [[ 1. ,  2.1],\n",
    "        [ 2. ,  1.1],\n",
    "        [ 1.3,  1. ],\n",
    "        [ 1. ,  1. ],\n",
    "        [ 2. ,  1. ]])\n",
    "     classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "     return datMat, classLabels\n",
    "\n",
    "datMat, classLabels = loadSimpData()\n",
    "\n",
    "xcord0 = []\n",
    "ycord0 = []\n",
    "xcord1 = []\n",
    "ycord1 = []\n",
    "markers =[]\n",
    "colors =[]\n",
    "\n",
    "for i in range(len(classLabels)):\n",
    "    if  classLabels[i] == 1.0:\n",
    "        xcord1.append(datMat[i, 0]), ycord1.append(datMat[i, 1])\n",
    "    else:\n",
    "        xcord0.append(datMat[i, 0]), ycord0.append(datMat[i, 1])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(xcord0, ycord0, marker='s', s=90)\n",
    "ax.scatter(xcord1, ycord1, marker='o', s=50, c='red')\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.title('my test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分类函数\n",
    "#(数据集，特征，阈值，阈值判定方法)\n",
    "def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0], 1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray\n",
    "#构建单层决策树（decision stump决策树桩）\n",
    "#(数据集，分类标签y,样本数据的权重向量D)\n",
    "def buildStump(dataArr, classLabels, D):\n",
    "    dataMatrix = np.mat(dataArr)\n",
    "    labelMat = np.mat(classLabels).T\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0\n",
    "    bestStump = {}\n",
    "    bestClassEst = np.mat(np.zeros((m, 1)))\n",
    "    minError = np.inf\n",
    "    for i in range(n):\n",
    "        rangeMin = dataMatrix[:,i].min()\n",
    "        rangeMax = dataMatrix[:,i].max()\n",
    "        stepSize = (rangeMax - rangeMin)\n",
    "        for j in range(-2, int(numSteps) + 1):\n",
    "            for inequal in ['lt', 'gt']:\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                #这里调用预测分类函数\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)\n",
    "                errArr = np.mat(np.ones((m, 1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClassEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.mat(np.ones((5,1)) / 5.0)\n",
    "bestStump, minError, bestClassEst = buildStump(datMat, classLabels, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dim': 1, 'thresh': 1.0, 'ineq': 'lt'}\n[[0.2]]\n[[ 1.]\n [ 1.]\n [-1.]\n [-1.]\n [-1.]]\n"
     ]
    }
   ],
   "source": [
    "print(bestStump)\n",
    "print(minError)\n",
    "print(bestClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单层决策树的训练过程 ：p117的公式\n",
    "#首先，基于样本的权重向量D（开始每个样本都是相同值）,\n",
    "# 然后训练一个弱分类器（单层决策树），并且得到分类的错误率（加权）和该分类器的权重值alpha\n",
    "#接着迭代：在同一个数据集中，调整D（分对的，权重降低，分错的，权重提高），再训练得到分类器\\错误率\\alpha\n",
    "#最后得到所有分类器的加权结果:sum(alpha[i]*y[i])\n",
    "def adaBoostTrainDS(dataArr, classLabels, numIt=40):\n",
    "    weakClassArr = []\n",
    "    m = np.shape(dataArr)[0]\n",
    "    D = np.mat(np.ones((m,1))/m)\n",
    "    aggClassEst=np.mat(np.zeros((m,1)))\n",
    "    errorRate=0.0\n",
    "    for i in range(numIt):\n",
    "        bestStump, error, classEst = buildStump(dataArr, classLabels, D)\n",
    "        alpha = float(0.5 * np.log((1.0 -error)/max(error,1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)\n",
    "        expon = np.multiply(-1*alpha*np.mat(classLabels).T, classEst)\n",
    "        D = np.multiply(D, np.exp(expon))\n",
    "        D = D/D.sum()\n",
    "        aggClassEst += alpha*classEst\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T, np.ones((m, 1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        if errorRate ==0.0:\n",
    "            break\n",
    "    return weakClassArr, aggClassEst, errorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakClassArr,aggClassEst,errorRate = adaBoostTrainDS(datMat,classLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaBoost分类函数\n",
    "#（数据集，训练好的多个分类器）\n",
    "#利用训练好的多个弱分类器，进行加权分类\n",
    "def adaClassify(dataToClass, classifierArr):\n",
    "    dataMatrix = np.mat(dataToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.mat(np.zeros((m, 1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'],\n",
    "                                 classifierArr[i]['thresh'],\n",
    "                                 classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n [-1.]]\n"
     ]
    }
   ],
   "source": [
    "pred = adaClassify([[5,5],[0,0]], weakClassArr)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用一个难数据集，测试一下\n",
    "def loadDataSet(fileName):\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))\n",
    "    dataMat = [];labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = []\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat - 1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat, labelMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练\n",
    "trainArr, trainLabel = loadDataSet('MachineLearningInAction/AdaBoost/horseColicTraining2.txt')\n",
    "weakClassArr1, aggClassEst1, errorRate1 = adaBoostTrainDS(trainArr, trainLabel, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35451505016722407\n"
     ]
    }
   ],
   "source": [
    "testArr, testLabel = loadDataSet('MachineLearningInAction/AdaBoost/horseColicTest2.txt')\n",
    "pred1 = adaClassify(testArr, weakClassArr1)\n",
    "testError = np.mean(pred1.A.ravel()!=np.array(testLabel))\n",
    "print(testError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at iters  1  train error= 0.3779264214046823 test error= 0.35451505016722407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at iters  10  train error= 0.35451505016722407 test error= 0.35451505016722407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at iters  30  train error= 0.33444816053511706 test error= 0.35451505016722407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at iters  50  train error= 0.31438127090301005 test error= 0.35451505016722407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at iters  100  train error= 0.3076923076923077 test error= 0.35451505016722407\n"
     ]
    }
   ],
   "source": [
    "#来看看分类器的个数的增加，算法的训练和测试效果\n",
    "#这里稍微改了一下adaBoostTrainDS(),最后一行多一个返回errorRate,注释掉一些输出\n",
    "for iters in [1, 10, 30, 50, 100]:\n",
    "    weakClassArr, aggClassEst, errorRate = adaBoostTrainDS(trainArr,trainLabel,iters)\n",
    "    pred = adaClassify(testArr, weakClassArr)\n",
    "    testError=np.mean(pred.A.ravel()!=np.array(testLabel))\n",
    "    print('at iters ', iters, ' train error=', errorRate, 'test error=', testError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC曲线绘制\n",
    "def plotROC(predStrengths, classLabels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    cur = (1.0,1.0)\n",
    "    ySum = 0.0\n",
    "    numPosClas = sum(np.array(classLabels) == 1.0)\n",
    "    yStep = 1/float(numPosClas)\n",
    "    xStep = 1/float(len(classLabels) - numPosClas)\n",
    "    sortedIndicies = predStrengths.argsort()\n",
    "    fig = plt.figure()\n",
    "    fig.clf()\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    for index in sortedIndicies.tolist()[0]:\n",
    "        if classLabels[index] == 1.0:\n",
    "            delX = 0; delY = yStep\n",
    "        else:\n",
    "            delX = xStep; delY = 0\n",
    "            ySum+=cur[1]\n",
    "        ax.plot([cur[0], cur[0]-delX],[cur[1],cur[1]-delY], c='b')\n",
    "        cur = (cur[0] -delX, cur[1]-delY)\n",
    "    ax.plot([0,1],[0,1],'b--')\n",
    "    plt.xlabel('假正例');plt.ylabel('真正例')\n",
    "    ax.axis([0,1,0,1])\n",
    "    plt.show()\n",
    "    print('AUC is:', ySum * xStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC is: 0.6976042343764506\n"
     ]
    }
   ],
   "source": [
    "trainArr, trainLabel = loadDataSet('MachineLearningInAction/AdaBoost/horseColicTraining2.txt')\n",
    "classifierArray, aggClassEst, tmp = adaBoostTrainDS(trainArr, trainLabel,10)\n",
    "plotROC(aggClassEst.T, trainLabel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
